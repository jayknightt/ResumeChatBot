# -*- coding: utf-8 -*-
"""ResumeChatBot.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JR8-jFZ0uVSANdXJFSwCs2R-s2BEK7jo
"""

!pip install langchain
!pip install openai
!pip install PyPDF2
!pip install faiss-cpu
!pip install tiktoken

from PyPDF2 import PdfReader
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores import ElasticVectorSearch, Pinecone, Weaviate, FAISS

import os
os.environ["OPENAI_API_KEY"] = "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"

from google.colab import files
import io
from PyPDF2 import PdfFileReader

uploaded = files.upload()
for name, data in uploaded.items():
    with io.BytesIO(data) as f:
        reader = PdfFileReader(f)

reader

raw_text = ''
for i, page in enumerate(reader.pages):
    text = page.extract_text()
    if text:
        raw_text += text

# raw_text

raw_text[:100]

text_splitter = CharacterTextSplitter(        
    separator = "\n",
    chunk_size = 1000,
    chunk_overlap  = 200,
    length_function = len,
)
texts = text_splitter.split_text(raw_text)

len(texts)

texts[0]

texts[1]

embeddings = OpenAIEmbeddings()

docsearch = FAISS.from_texts(texts, embeddings)

docsearch

from langchain.chains.question_answering import load_qa_chain
from langchain.llms import OpenAI

chain = load_qa_chain(OpenAI(), chain_type="stuff")

query = "what are the skills and experience of the candidate?"
docs = docsearch.similarity_search(query)
chain.run(input_documents=docs, question=query)

query = "What was the cost of training the GPT4all model?"
docs = docsearch.similarity_search(query)
chain.run(input_documents=docs, question=query)

query = "How was the model trained?"
docs = docsearch.similarity_search(query)
chain.run(input_documents=docs, question=query)

query = "what was the size of the training dataset?"
docs = docsearch.similarity_search(query)
chain.run(input_documents=docs, question=query)

query = "How is this different from other models?"
docs = docsearch.similarity_search(query)
chain.run(input_documents=docs, question=query)

query = "What is Google Bard?"
docs = docsearch.similarity_search(query)
chain.run(input_documents=docs, question=query)

!pip install PyPDF2
!pip install spacy
!python -m spacy download en_core_web_sm
from google.colab import files
import io
from PyPDF2 import PdfFileReader
import spacy
from transformers import pipeline

nlp = spacy.load('en_core_web_sm')
chatbot = pipeline('text-generation', model='EleutherAI/gpt-neo-1.3B')

html = """
<!DOCTYPE html>
<html>
  <body>
    <h2>Resume Analyzer</h2>
    <form id="pdf-form">
      <label for="pdf-file">Upload a PDF file:</label>
      <input type="file" id="pdf-file" name="pdf-file"><br><br>
      <button type="submit">Submit</button>
    </form>
    <div id="output"></div>
  </body>
  <script>
    const form = document.querySelector('#pdf-form');
    const output = document.querySelector('#output');

    form.addEventListener('submit', async (event) => {
      event.preventDefault();

      const formData = new FormData(form);
      const response = await fetch('/analyze', {
        method: 'POST',
        body: formData
      });

      const text = await response.text();
      output.innerHTML = text;
    });
  </script>
</html>
"""

def analyze_pdf():
    uploaded_file = next(iter(files.upload().values()))
    with io.BytesIO(uploaded_file) as f:
        reader = PdfFileReader(f)
        text = ''
        for i in range(reader.getNumPages()):
            page = reader.getPage(i)
            text += page.extractText()
        doc = nlp(text)
        skills = []
        for ent in doc.ents:
            if ent.label_ == 'SKILL':
                skills.append(ent.text)
        if len(skills) == 0:
            output_text = "No relevant skills found in the resume."
        else:
            output_text = "Relevant skills found in the resume:\n\n"
            for i, skill in enumerate(skills):
                output_text += f"{i+1}. {skill}\n"
        response = {"text": output_text}
        return response

def generate_response(question):
    response = chatbot(question)[0]['generated_text']
    return {"text": response}

from flask import Flask, request, jsonify
app = Flask(__name__)

@app.route('/', methods=['GET'])
def home():
    return html

@app.route('/analyze', methods=['POST'])
def analyze():
    response = analyze_pdf()
    return jsonify(response)

@app.route('/chatbot', methods=['POST'])
def chatbot():
    question = request.form['question']
    response = generate_response(question)
    return jsonify(response)

# Run app
app.run()